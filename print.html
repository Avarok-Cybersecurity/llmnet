<!DOCTYPE HTML>
<html lang="en" class="coal sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>llmnet - LLM Pipeline Orchestration</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="The future is small models routed to — intelligently">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "coal";
            const default_dark_theme = "coal";
            window.path_to_searchindex_js = "searchindex-448e645d.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-9ca9bf67.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('coal')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">llmnet - LLM Pipeline Orchestration</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/your-org/llmnet" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><strong>llmnet</strong> is a CLI tool for orchestrating LLM pipelines using small, efficient models routed intelligently.</p>
<blockquote>
<p><em>The future is small models routed to — intelligently</em></p>
</blockquote>
<h2 id="what-is-llmnet"><a class="header" href="#what-is-llmnet">What is llmnet?</a></h2>
<p>llmnet allows you to define multi-model pipelines where:</p>
<ul>
<li>A <strong>router</strong> model intelligently directs requests to specialized handlers</li>
<li><strong>Handler</strong> models are specialized for specific domains or tasks</li>
<li><strong>Hooks</strong> execute custom logic before and after LLM calls</li>
<li><strong>Secrets</strong> are securely loaded from environment files, variables, or vaults</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<ul>
<li><strong>Declarative Configuration</strong>: Define your entire pipeline in a single JSON file</li>
<li><strong>Intelligent Routing</strong>: Router models select the best handler for each request</li>
<li><strong>Conditional Routing</strong>: Route based on input characteristics (word count, hop count, etc.)</li>
<li><strong>Hooks System</strong>: Execute pre/post processing with REST, Shell, WebSocket, or gRPC functions</li>
<li><strong>Secret Management</strong>: Load credentials from env files, system environment, or HashiCorp Vault</li>
<li><strong>Multi-Layer Pipelines</strong>: Chain handlers through multiple processing layers</li>
<li><strong>Local &amp; Remote Models</strong>: Use Ollama, vLLM, llama.cpp, or external APIs</li>
</ul>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                         User Request                            │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Layer 0: Router                            │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │ Pre-hooks → Router LLM → Post-hooks                      │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
                                │
                    ┌───────────┴───────────┐
                    ▼                       ▼
┌─────────────────────────────┐  ┌─────────────────────────────┐
│    Layer 1: Sales Agent     │  │   Layer 1: Support Agent    │
│  ┌───────────────────────┐  │  │  ┌───────────────────────┐  │
│  │ Pre → LLM → Post      │  │  │  │ Pre → LLM → Post      │  │
│  └───────────────────────┘  │  │  └───────────────────────┘  │
└─────────────────────────────┘  └─────────────────────────────┘
                    │                       │
                    └───────────┬───────────┘
                                ▼
                    ┌─────────────────────────────┐
                    │         Output              │
                    └─────────────────────────────┘
</code></pre>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Jump to the <a href="#quick-start">Quick Start</a> guide to create your first pipeline in minutes.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<h2 id="from-source"><a class="header" href="#from-source">From Source</a></h2>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/your-org/llmnet.git
cd llmnet

# Build in release mode
cargo build --release

# The binary is at target/release/llmnet
./target/release/llmnet --help
</code></pre>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li><strong>Rust 1.75+</strong>: Install via <a href="https://rustup.rs/">rustup</a></li>
<li><strong>LLM Backend</strong> (one of):
<ul>
<li><a href="https://ollama.ai/">Ollama</a> - Local models</li>
<li><a href="https://docs.vllm.ai/">vLLM</a> - Production GPU inference</li>
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> - CPU/Metal inference</li>
<li>External API (OpenAI-compatible)</li>
</ul>
</li>
</ul>
<h2 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h2>
<pre><code class="language-bash">llmnet --version
llmnet validate examples/basic-router.json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>This guide gets you up and running with llmnet in 5 minutes.</p>
<h2 id="1-create-a-composition-file"><a class="header" href="#1-create-a-composition-file">1. Create a Composition File</a></h2>
<p>Create <code>my-pipeline.json</code>:</p>
<pre><code class="language-json">{
  "models": {
    "router": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1",
      "api-key": "ollama"
    },
    "handler": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1",
      "api-key": "ollama"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "router",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "assistant",
      "layer": 1,
      "model": "handler",
      "adapter": "openai-api",
      "use-case": "General assistant for all queries",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="2-start-ollama"><a class="header" href="#2-start-ollama">2. Start Ollama</a></h2>
<pre><code class="language-bash"># Pull a model
ollama pull llama3.2:3b

# Ollama runs on localhost:11434 by default
</code></pre>
<h2 id="3-validate-your-configuration"><a class="header" href="#3-validate-your-configuration">3. Validate Your Configuration</a></h2>
<pre><code class="language-bash">llmnet validate my-pipeline.json
</code></pre>
<h2 id="4-start-the-server"><a class="header" href="#4-start-the-server">4. Start the Server</a></h2>
<pre><code class="language-bash">llmnet serve my-pipeline.json
</code></pre>
<h2 id="5-send-a-request"><a class="header" href="#5-send-a-request">5. Send a Request</a></h2>
<pre><code class="language-bash">curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li>Learn about <a href="#models">Models Configuration</a></li>
<li>Add multiple handlers with <a href="#architecture">Architecture</a></li>
<li>Set up pre/post processing with <a href="#hooks">Hooks</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="your-first-pipeline"><a class="header" href="#your-first-pipeline">Your First Pipeline</a></h1>
<p>This guide walks through creating a complete router → handler → output pipeline.</p>
<h2 id="understanding-the-structure"><a class="header" href="#understanding-the-structure">Understanding the Structure</a></h2>
<p>A llmnet pipeline consists of:</p>
<ul>
<li><strong>Models</strong>: LLM configurations (local or remote)</li>
<li><strong>Architecture</strong>: Nodes organized in layers</li>
<li><strong>Functions</strong>: Custom operations for hooks (optional)</li>
<li><strong>Secrets</strong>: Credential sources (optional)</li>
</ul>
<h2 id="step-1-define-models"><a class="header" href="#step-1-define-models">Step 1: Define Models</a></h2>
<pre><code class="language-json">{
  "models": {
    "small-router": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    },
    "large-handler": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  }
}
</code></pre>
<h2 id="step-2-create-architecture"><a class="header" href="#step-2-create-architecture">Step 2: Create Architecture</a></h2>
<pre><code class="language-json">{
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "small-router",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "expert",
      "layer": 1,
      "model": "large-handler",
      "adapter": "openai-api",
      "use-case": "Detailed expert responses",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="step-3-run-it"><a class="header" href="#step-3-run-it">Step 3: Run It</a></h2>
<pre><code class="language-bash">llmnet validate my-pipeline.json
llmnet serve my-pipeline.json
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li>Add more handlers: <a href="#architecture">Architecture</a></li>
<li>Add hooks: <a href="#hooks">Hooks</a></li>
<li>Add secrets: <a href="#secrets">Secrets</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="composition-files"><a class="header" href="#composition-files">Composition Files</a></h1>
<p>A composition file defines your complete LLM pipeline in JSON format.</p>
<h2 id="structure"><a class="header" href="#structure">Structure</a></h2>
<pre><code class="language-json">{
  "secrets": { },      // Optional: credential sources
  "functions": { },    // Optional: hook functions
  "models": { },       // Required: LLM configurations
  "architecture": [ ]  // Required: pipeline nodes
}
</code></pre>
<h2 id="minimal-example"><a class="header" href="#minimal-example">Minimal Example</a></h2>
<pre><code class="language-json">{
  "models": {
    "default": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "default",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "handler",
      "layer": 1,
      "model": "default",
      "adapter": "openai-api",
      "use-case": "General assistant",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="validation"><a class="header" href="#validation">Validation</a></h2>
<p>Always validate your composition before running:</p>
<pre><code class="language-bash">llmnet validate my-pipeline.json
</code></pre>
<p>This checks:</p>
<ul>
<li>JSON syntax</li>
<li>Required fields</li>
<li>Model references</li>
<li>Function references in hooks</li>
<li>Output node existence</li>
<li>Layer connectivity</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="models"><a class="header" href="#models">Models</a></h1>
<p>Models define how llmnet connects to LLMs.</p>
<h2 id="external-models"><a class="header" href="#external-models">External Models</a></h2>
<p>Connect to OpenAI-compatible APIs:</p>
<pre><code class="language-json">{
  "models": {
    "gpt4": {
      "type": "external",
      "interface": "openai-api",
      "url": "https://api.openai.com/v1",
      "api-key": "$secrets.openai.API_KEY"
    },
    "ollama-local": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1",
      "api-key": "ollama"
    }
  }
}
</code></pre>
<h2 id="model-override"><a class="header" href="#model-override">Model Override</a></h2>
<p>Override the model name per-node:</p>
<pre><code class="language-json">{
  "name": "router",
  "model": "ollama-local",
  "extra-options": {
    "model_override": "llama3.2:3b"
  }
}
</code></pre>
<h2 id="spawnable-models"><a class="header" href="#spawnable-models">Spawnable Models</a></h2>
<p>Define models to be spawned locally:</p>
<pre><code class="language-json">{
  "models": {
    "local-llama": {
      "type": "ollama",
      "model": "llama3.2:3b",
      "options": {
        "num_ctx": 4096,
        "num_gpu": 1
      }
    }
  }
}
</code></pre>
<p>Supported spawnable types:</p>
<ul>
<li><code>ollama</code>: Ollama models</li>
<li><code>vllm</code>: vLLM server</li>
<li><code>llamacpp</code>: llama.cpp server</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>The architecture defines nodes in your pipeline and how they connect.</p>
<h2 id="node-properties"><a class="header" href="#node-properties">Node Properties</a></h2>
<pre><code class="language-json">{
  "name": "sales-agent",
  "layer": 1,
  "model": "handler-model",
  "adapter": "openai-api",
  "use-case": "Handle sales inquiries",
  "context": "You are a helpful sales assistant...",
  "if": "$WORD_COUNT &gt; 10",
  "hooks": {
    "pre": [],
    "post": []
  },
  "output-to": [2]
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>string</td><td>Yes</td><td>Unique node identifier</td></tr>
<tr><td><code>layer</code></td><td>number</td><td>No</td><td>Processing layer (0 = router)</td></tr>
<tr><td><code>model</code></td><td>string</td><td>No</td><td>Reference to a model</td></tr>
<tr><td><code>adapter</code></td><td>string</td><td>Yes</td><td><code>openai-api</code> or <code>output</code></td></tr>
<tr><td><code>use-case</code></td><td>string</td><td>No</td><td>Description for routing</td></tr>
<tr><td><code>context</code></td><td>string</td><td>No</td><td>System prompt</td></tr>
<tr><td><code>if</code></td><td>string</td><td>No</td><td>Condition for routing</td></tr>
<tr><td><code>hooks</code></td><td>object</td><td>No</td><td>Pre/post hooks</td></tr>
<tr><td><code>output-to</code></td><td>array</td><td>No</td><td>Target layers or node names</td></tr>
</tbody>
</table>
</div>
<h2 id="layers"><a class="header" href="#layers">Layers</a></h2>
<p>Organize nodes into layers:</p>
<ul>
<li><strong>Layer 0</strong>: Router (entry point)</li>
<li><strong>Layer 1-N</strong>: Handler nodes</li>
<li><strong>Output</strong>: Final output node</li>
</ul>
<h2 id="output-targets"><a class="header" href="#output-targets">Output Targets</a></h2>
<p>Specify targets by layer number or node name:</p>
<pre><code class="language-json">// By layer number
"output-to": [1, 2]

// By node name
"output-to": ["sales", "support", "output"]
</code></pre>
<h2 id="required-output-node"><a class="header" href="#required-output-node">Required Output Node</a></h2>
<p>Every composition must have an output node:</p>
<pre><code class="language-json">{
  "name": "output",
  "adapter": "output"
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="secrets"><a class="header" href="#secrets">Secrets</a></h1>
<p>Secrets allow you to securely load credentials from various sources without hardcoding them in your composition files.</p>
<h2 id="secret-sources"><a class="header" href="#secret-sources">Secret Sources</a></h2>
<h3 id="environment-file"><a class="header" href="#environment-file">Environment File</a></h3>
<p>Load from a <code>.env</code> file:</p>
<pre><code class="language-json">{
  "secrets": {
    "api-creds": {
      "source": "env-file",
      "path": "~/.config/llmnet/.env",
      "variables": ["API_KEY", "API_SECRET"]
    }
  }
}
</code></pre>
<p>The <code>.env</code> file format:</p>
<pre><code class="language-env"># Comment lines are ignored
API_KEY=sk-abc123...
API_SECRET="quoted values work too"
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>path</code></td><td>string</td><td>required</td><td>Path to .env file (~ is expanded)</td></tr>
<tr><td><code>variables</code></td><td>array</td><td><code>[]</code></td><td>Variables to load (empty = load all)</td></tr>
</tbody>
</table>
</div>
<h3 id="system-environment"><a class="header" href="#system-environment">System Environment</a></h3>
<p>Load from a system environment variable:</p>
<pre><code class="language-json">{
  "secrets": {
    "hf-token": {
      "source": "env",
      "variable": "HF_TOKEN"
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>variable</code></td><td>string</td><td>Environment variable name</td></tr>
</tbody>
</table>
</div>
<h3 id="hashicorp-vault"><a class="header" href="#hashicorp-vault">HashiCorp Vault</a></h3>
<p>Load from Vault KV v2:</p>
<pre><code class="language-json">{
  "secrets": {
    "vault-creds": {
      "source": "vault",
      "address": "https://vault.example.com",
      "path": "secret/data/llmnet/api",
      "variables": ["API_KEY", "DB_PASSWORD"],
      "token-env": "VAULT_TOKEN"
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>address</code></td><td>string</td><td>required</td><td>Vault server URL</td></tr>
<tr><td><code>path</code></td><td>string</td><td>required</td><td>KV v2 path</td></tr>
<tr><td><code>variables</code></td><td>array</td><td><code>[]</code></td><td>Variables to load (empty = load all)</td></tr>
<tr><td><code>token-env</code></td><td>string</td><td><code>VAULT_TOKEN</code></td><td>Env var containing Vault token</td></tr>
</tbody>
</table>
</div>
<h2 id="using-secrets"><a class="header" href="#using-secrets">Using Secrets</a></h2>
<p>Reference secrets using the <code>$secrets.{name}.{variable}</code> syntax:</p>
<pre><code class="language-json">{
  "functions": {
    "send-to-api": {
      "type": "rest",
      "method": "POST",
      "url": "https://api.example.com/data",
      "headers": {
        "Authorization": "Bearer $secrets.api-creds.API_KEY",
        "X-Secret": "$secrets.api-creds.API_SECRET"
      }
    }
  },
  "models": {
    "openai": {
      "type": "external",
      "interface": "openai-api",
      "url": "https://api.openai.com/v1",
      "api-key": "$secrets.api-creds.OPENAI_KEY"
    }
  }
}
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Never commit secrets</strong>: Keep <code>.env</code> files out of version control</li>
<li><strong>Use specific variables</strong>: List only the variables you need</li>
<li><strong>Prefer Vault for production</strong>: More secure than file-based secrets</li>
<li><strong>Validate early</strong>: Use <code>llmnet validate</code> to catch missing secrets</li>
</ol>
<h2 id="example-multi-source-secrets"><a class="header" href="#example-multi-source-secrets">Example: Multi-Source Secrets</a></h2>
<pre><code class="language-json">{
  "secrets": {
    "local-dev": {
      "source": "env-file",
      "path": "./.env.local",
      "variables": ["DEV_API_KEY"]
    },
    "ci-token": {
      "source": "env",
      "variable": "CI_API_TOKEN"
    },
    "production": {
      "source": "vault",
      "address": "https://vault.prod.example.com",
      "path": "secret/data/llmnet/prod",
      "variables": ["PROD_API_KEY", "PROD_DB_URL"]
    }
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="functions"><a class="header" href="#functions">Functions</a></h1>
<p>Functions are reusable operations that can be called from hooks. They support REST APIs, shell commands, WebSockets, and gRPC.</p>
<h2 id="function-types"><a class="header" href="#function-types">Function Types</a></h2>
<h3 id="rest"><a class="header" href="#rest">REST</a></h3>
<p>HTTP requests to external services.</p>
<pre><code class="language-json">{
  "functions": {
    "log-request": {
      "type": "rest",
      "method": "POST",
      "url": "https://api.example.com/log",
      "headers": {
        "Authorization": "Bearer $secrets.api.TOKEN",
        "Content-Type": "application/json"
      },
      "body": {
        "node": "$NODE",
        "input": "$INPUT",
        "output": "$OUTPUT"
      },
      "timeout": 10
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>method</code></td><td>string</td><td><code>GET</code></td><td>HTTP method: GET, POST, PUT, PATCH, DELETE</td></tr>
<tr><td><code>url</code></td><td>string</td><td>required</td><td>Target URL (supports variable substitution)</td></tr>
<tr><td><code>headers</code></td><td>object</td><td><code>{}</code></td><td>HTTP headers</td></tr>
<tr><td><code>body</code></td><td>object</td><td>optional</td><td>JSON body for POST/PUT/PATCH</td></tr>
<tr><td><code>timeout</code></td><td>number</td><td><code>30</code></td><td>Timeout in seconds</td></tr>
</tbody>
</table>
</div>
<h3 id="shell"><a class="header" href="#shell">Shell</a></h3>
<p>Execute local commands.</p>
<pre><code class="language-json">{
  "functions": {
    "validate-json": {
      "type": "shell",
      "command": "python",
      "args": ["validate.py", "--input", "$OUTPUT"],
      "env": {
        "PYTHONPATH": "/app/lib"
      },
      "cwd": "/app/scripts",
      "timeout": 30
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>command</code></td><td>string</td><td>required</td><td>Executable to run</td></tr>
<tr><td><code>args</code></td><td>array</td><td><code>[]</code></td><td>Command arguments</td></tr>
<tr><td><code>env</code></td><td>object</td><td><code>{}</code></td><td>Environment variables</td></tr>
<tr><td><code>cwd</code></td><td>string</td><td>optional</td><td>Working directory</td></tr>
<tr><td><code>timeout</code></td><td>number</td><td><code>30</code></td><td>Timeout in seconds</td></tr>
</tbody>
</table>
</div>
<h3 id="websocket"><a class="header" href="#websocket">WebSocket</a></h3>
<p>Send messages to WebSocket servers.</p>
<pre><code class="language-json">{
  "functions": {
    "notify-dashboard": {
      "type": "websocket",
      "url": "wss://dashboard.example.com/ws",
      "headers": {
        "Authorization": "Bearer $secrets.ws.TOKEN"
      },
      "message": {
        "event": "node_complete",
        "node": "$NODE",
        "output": "$OUTPUT"
      }
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>url</code></td><td>string</td><td>required</td><td>WebSocket URL</td></tr>
<tr><td><code>headers</code></td><td>object</td><td><code>{}</code></td><td>Connection headers</td></tr>
<tr><td><code>message</code></td><td>object</td><td>optional</td><td>JSON message to send</td></tr>
</tbody>
</table>
</div>
<h3 id="grpc"><a class="header" href="#grpc">gRPC</a></h3>
<p>Call gRPC services.</p>
<pre><code class="language-json">{
  "functions": {
    "check-quota": {
      "type": "grpc",
      "address": "quota-service:50051",
      "service": "QuotaService",
      "method": "CheckQuota",
      "request": {
        "user_id": "$USER_ID",
        "tokens": "$TOKEN_COUNT"
      },
      "timeout": 5
    }
  }
}
</code></pre>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>address</code></td><td>string</td><td>required</td><td>gRPC server address</td></tr>
<tr><td><code>service</code></td><td>string</td><td>required</td><td>Service name</td></tr>
<tr><td><code>method</code></td><td>string</td><td>required</td><td>Method name</td></tr>
<tr><td><code>request</code></td><td>object</td><td>optional</td><td>Request payload</td></tr>
<tr><td><code>timeout</code></td><td>number</td><td><code>30</code></td><td>Timeout in seconds</td></tr>
</tbody>
</table>
</div>
<h2 id="variable-substitution"><a class="header" href="#variable-substitution">Variable Substitution</a></h2>
<p>Functions support variable substitution in strings:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Variable</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>$INPUT</code></td><td>Current input content</td></tr>
<tr><td><code>$OUTPUT</code></td><td>Current output (post-hooks only)</td></tr>
<tr><td><code>$NODE</code></td><td>Current node name</td></tr>
<tr><td><code>$PREV_NODE</code></td><td>Previous node name</td></tr>
<tr><td><code>$TIMESTAMP</code></td><td>ISO 8601 timestamp</td></tr>
<tr><td><code>$REQUEST_ID</code></td><td>Unique request identifier</td></tr>
<tr><td><code>$secrets.{name}.{var}</code></td><td>Secret value</td></tr>
</tbody>
</table>
</div>
<h2 id="transform-response-format"><a class="header" href="#transform-response-format">Transform Response Format</a></h2>
<p>For transform-mode hooks, the function should return the value to use:</p>
<pre><code class="language-json">// Good: Returns the new value directly
"Hello, transformed output!"

// Also good: Object that replaces output
{"result": 42, "status": "validated"}
</code></pre>
<p>The returned value replaces the current data. For observe-mode hooks, the return value is ignored.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="hooks"><a class="header" href="#hooks">Hooks</a></h1>
<p>Hooks allow you to execute custom logic before and after LLM calls. They’re defined at the node level and can observe, transform, or validate data.</p>
<h2 id="hook-modes"><a class="header" href="#hook-modes">Hook Modes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Mode</th><th>Behavior</th></tr>
</thead>
<tbody>
<tr><td><code>observe</code></td><td>Fire-and-forget. Runs asynchronously, doesn’t affect pipeline data.</td></tr>
<tr><td><code>transform</code></td><td>Waits for result. Can modify input (pre) or output (post).</td></tr>
</tbody>
</table>
</div>
<h2 id="hook-configuration"><a class="header" href="#hook-configuration">Hook Configuration</a></h2>
<pre><code class="language-json">{
  "architecture": [
    {
      "name": "processor",
      "layer": 1,
      "model": "my-model",
      "adapter": "openai-api",
      "hooks": {
        "pre": [
          {
            "function": "log-input",
            "mode": "observe",
            "on_failure": "continue"
          },
          {
            "function": "validate-input",
            "mode": "transform",
            "on_failure": "abort",
            "if": "$WORD_COUNT &gt; 10"
          }
        ],
        "post": [
          {
            "function": "validate-output",
            "mode": "transform",
            "on_failure": "abort"
          }
        ]
      },
      "output-to": ["output"]
    }
  ]
}
</code></pre>
<h2 id="hook-properties"><a class="header" href="#hook-properties">Hook Properties</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Property</th><th>Type</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>function</code></td><td>string</td><td>required</td><td>Name of the function to execute</td></tr>
<tr><td><code>mode</code></td><td>string</td><td><code>observe</code></td><td><code>observe</code> or <code>transform</code></td></tr>
<tr><td><code>on_failure</code></td><td>string</td><td><code>continue</code></td><td><code>continue</code> or <code>abort</code></td></tr>
<tr><td><code>if</code></td><td>string</td><td>optional</td><td>Condition expression</td></tr>
</tbody>
</table>
</div>
<h2 id="failure-actions"><a class="header" href="#failure-actions">Failure Actions</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Action</th><th>Behavior</th></tr>
</thead>
<tbody>
<tr><td><code>continue</code></td><td>Log error and proceed with original data</td></tr>
<tr><td><code>abort</code></td><td>Stop pipeline execution and return error</td></tr>
</tbody>
</table>
</div>
<h2 id="pre-vs-post-hooks"><a class="header" href="#pre-vs-post-hooks">Pre vs Post Hooks</a></h2>
<h3 id="pre-hooks"><a class="header" href="#pre-hooks">Pre-hooks</a></h3>
<p>Execute <strong>before</strong> the LLM call:</p>
<ul>
<li>Access: <code>$INPUT</code>, <code>$NODE</code>, <code>$REQUEST_ID</code>, <code>$TIMESTAMP</code></li>
<li>Transform mode: Can modify the input sent to the LLM</li>
</ul>
<h3 id="post-hooks"><a class="header" href="#post-hooks">Post-hooks</a></h3>
<p>Execute <strong>after</strong> the LLM call:</p>
<ul>
<li>Access: All pre-hook variables plus <code>$OUTPUT</code></li>
<li>Transform mode: Can modify the output before passing to next node</li>
</ul>
<h2 id="conditional-hooks"><a class="header" href="#conditional-hooks">Conditional Hooks</a></h2>
<p>Use the <code>if</code> property to conditionally execute hooks:</p>
<pre><code class="language-json">{
  "function": "complex-validation",
  "mode": "transform",
  "if": "$WORD_COUNT &gt;= 50"
}
</code></pre>
<p>See <a href="#conditional-routing">Conditional Routing</a> for available variables and operators.</p>
<h2 id="example-logging-and-validation"><a class="header" href="#example-logging-and-validation">Example: Logging and Validation</a></h2>
<pre><code class="language-json">{
  "functions": {
    "log-request": {
      "type": "rest",
      "method": "POST",
      "url": "https://logging.example.com/api/log",
      "headers": {
        "Authorization": "Bearer $secrets.logging.API_KEY"
      },
      "body": {
        "node": "$NODE",
        "input": "$INPUT",
        "timestamp": "$TIMESTAMP"
      }
    },
    "validate-json": {
      "type": "shell",
      "command": "python",
      "args": ["validate.py", "--input", "$OUTPUT"],
      "timeout": 10
    }
  },
  "architecture": [
    {
      "name": "json-generator",
      "layer": 1,
      "model": "gpt-4",
      "adapter": "openai-api",
      "hooks": {
        "pre": [
          {"function": "log-request", "mode": "observe"}
        ],
        "post": [
          {"function": "validate-json", "mode": "transform", "on_failure": "abort"}
        ]
      },
      "output-to": ["output"]
    }
  ]
}
</code></pre>
<h2 id="hook-chaining"><a class="header" href="#hook-chaining">Hook Chaining</a></h2>
<p>Multiple hooks in a list execute sequentially. For transform mode, each hook receives the output of the previous:</p>
<pre><code class="language-json">{
  "post": [
    {"function": "step1", "mode": "transform"},
    {"function": "step2", "mode": "transform"},
    {"function": "step3", "mode": "transform"}
  ]
}
</code></pre>
<p>Flow: <code>LLM output → step1 → step2 → step3 → final output</code></p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="conditional-routing"><a class="header" href="#conditional-routing">Conditional Routing</a></h1>
<p>Conditions allow dynamic routing based on request characteristics.</p>
<h2 id="available-variables"><a class="header" href="#available-variables">Available Variables</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Variable</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>$WORD_COUNT</code></td><td>number</td><td>Word count of current input</td></tr>
<tr><td><code>$INPUT_LENGTH</code></td><td>number</td><td>Character count of input</td></tr>
<tr><td><code>$HOP_COUNT</code></td><td>number</td><td>Number of nodes visited</td></tr>
<tr><td><code>$PREV_NODE</code></td><td>string</td><td>Name of previous node</td></tr>
<tr><td><code>$CURRENT_LAYER</code></td><td>number</td><td>Current processing layer</td></tr>
</tbody>
</table>
</div>
<h2 id="operators"><a class="header" href="#operators">Operators</a></h2>
<h3 id="existence-check"><a class="header" href="#existence-check">Existence Check</a></h3>
<pre><code class="language-json">"if": "$API_KEY"
</code></pre>
<p>Passes if variable exists and is non-empty.</p>
<h3 id="equality"><a class="header" href="#equality">Equality</a></h3>
<pre><code class="language-json">"if": "$PREV_NODE == \"router\""
</code></pre>
<h3 id="inequality"><a class="header" href="#inequality">Inequality</a></h3>
<pre><code class="language-json">"if": "$MODE != \"debug\""
</code></pre>
<h3 id="numeric-comparisons"><a class="header" href="#numeric-comparisons">Numeric Comparisons</a></h3>
<pre><code class="language-json">"if": "$WORD_COUNT &gt; 50"
"if": "$WORD_COUNT &gt;= 50"
"if": "$HOP_COUNT &lt; 3"
"if": "$INPUT_LENGTH &lt;= 1000"
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="route-long-inputs-to-different-handler"><a class="header" href="#route-long-inputs-to-different-handler">Route Long Inputs to Different Handler</a></h3>
<pre><code class="language-json">{
  "architecture": [
    {"name": "router", "layer": 0, "output-to": [1]},
    {
      "name": "short-handler",
      "layer": 1,
      "if": "$WORD_COUNT &lt; 20",
      "use-case": "Quick responses"
    },
    {
      "name": "long-handler",
      "layer": 1,
      "if": "$WORD_COUNT &gt;= 20",
      "use-case": "Detailed responses"
    }
  ]
}
</code></pre>
<h3 id="prevent-infinite-loops"><a class="header" href="#prevent-infinite-loops">Prevent Infinite Loops</a></h3>
<pre><code class="language-json">{
  "name": "recursive-handler",
  "layer": 1,
  "if": "$HOP_COUNT &lt; 5",
  "output-to": [1]
}
</code></pre>
<h3 id="chain-specific-processing"><a class="header" href="#chain-specific-processing">Chain-Specific Processing</a></h3>
<pre><code class="language-json">{
  "name": "refiner-for-sales",
  "layer": 2,
  "if": "$PREV_NODE == \"sales\"",
  "use-case": "Refine sales responses"
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="cli-overview"><a class="header" href="#cli-overview">CLI Overview</a></h1>
<p>llmnet provides a command-line interface for managing LLM pipelines.</p>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<pre><code class="language-bash">llmnet [OPTIONS] &lt;COMMAND&gt;
</code></pre>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Command</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>run</code></td><td>Run a pipeline with a single prompt</td></tr>
<tr><td><code>serve</code></td><td>Start the HTTP server</td></tr>
<tr><td><code>validate</code></td><td>Validate a composition file</td></tr>
<tr><td><code>deploy</code></td><td>Deploy to a cluster</td></tr>
<tr><td><code>status</code></td><td>Show cluster status</td></tr>
</tbody>
</table>
</div>
<h2 id="global-options"><a class="header" href="#global-options">Global Options</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>-h, --help</code></td><td>Print help</td></tr>
<tr><td><code>-V, --version</code></td><td>Print version</td></tr>
<tr><td><code>--config &lt;FILE&gt;</code></td><td>Config file path</td></tr>
<tr><td><code>--verbose</code></td><td>Verbose output</td></tr>
</tbody>
</table>
</div>
<h2 id="quick-examples"><a class="header" href="#quick-examples">Quick Examples</a></h2>
<pre><code class="language-bash"># Validate configuration
llmnet validate pipeline.json

# Start server on port 8080
llmnet serve pipeline.json --port 8080

# Single prompt
llmnet run pipeline.json "What is machine learning?"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="run"><a class="header" href="#run">run</a></h1>
<p>Execute a single prompt through the pipeline.</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<pre><code class="language-bash">llmnet run &lt;COMPOSITION&gt; &lt;PROMPT&gt;
</code></pre>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<pre><code class="language-bash">llmnet run pipeline.json "Explain quantum computing"
</code></pre>
<h2 id="options"><a class="header" href="#options">Options</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>--format</code></td><td>Output format: <code>text</code>, <code>json</code></td></tr>
<tr><td><code>--trace</code></td><td>Show execution trace</td></tr>
</tbody>
</table>
</div>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="serve"><a class="header" href="#serve">serve</a></h1>
<p>Start the HTTP server for the pipeline.</p>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<pre><code class="language-bash">llmnet serve &lt;COMPOSITION&gt; [OPTIONS]
</code></pre>
<h2 id="options-1"><a class="header" href="#options-1">Options</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>--port</code></td><td>8080</td><td>HTTP port</td></tr>
<tr><td><code>--host</code></td><td>127.0.0.1</td><td>Bind address</td></tr>
</tbody>
</table>
</div>
<h2 id="example-1"><a class="header" href="#example-1">Example</a></h2>
<pre><code class="language-bash">llmnet serve pipeline.json --port 3000 --host 0.0.0.0
</code></pre>
<h2 id="endpoints"><a class="header" href="#endpoints">Endpoints</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Endpoint</th><th>Method</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>/health</code></td><td>GET</td><td>Health check</td></tr>
<tr><td><code>/v1/chat/completions</code></td><td>POST</td><td>Chat completion</td></tr>
</tbody>
</table>
</div>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="validate"><a class="header" href="#validate">validate</a></h1>
<p>Validate a composition file without running it.</p>
<h2 id="usage-2"><a class="header" href="#usage-2">Usage</a></h2>
<pre><code class="language-bash">llmnet validate &lt;COMPOSITION&gt;
</code></pre>
<h2 id="example-2"><a class="header" href="#example-2">Example</a></h2>
<pre><code class="language-bash">llmnet validate my-pipeline.json
</code></pre>
<h2 id="what-it-checks"><a class="header" href="#what-it-checks">What It Checks</a></h2>
<ul>
<li>JSON syntax</li>
<li>Required fields</li>
<li>Model references</li>
<li>Architecture connectivity</li>
<li>Output node existence</li>
<li>Function references in hooks</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="deploy"><a class="header" href="#deploy">deploy</a></h1>
<p>Deploy a pipeline to a cluster.</p>
<h2 id="usage-3"><a class="header" href="#usage-3">Usage</a></h2>
<pre><code class="language-bash">llmnet deploy &lt;COMPOSITION&gt; [OPTIONS]
</code></pre>
<h2 id="options-2"><a class="header" href="#options-2">Options</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>--context</code></td><td>Target cluster context</td></tr>
<tr><td><code>--replicas</code></td><td>Number of replicas</td></tr>
</tbody>
</table>
</div>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="status"><a class="header" href="#status">status</a></h1>
<p>Show the status of a deployed pipeline.</p>
<h2 id="usage-4"><a class="header" href="#usage-4">Usage</a></h2>
<pre><code class="language-bash">llmnet status [OPTIONS]
</code></pre>
<h2 id="options-3"><a class="header" href="#options-3">Options</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>--context</code></td><td>Target cluster context</td></tr>
<tr><td><code>--wide</code></td><td>Show additional details</td></tr>
</tbody>
</table>
</div>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="basic-chatbot"><a class="header" href="#basic-chatbot">Basic Chatbot</a></h1>
<p>A minimal pipeline with a router and single handler.</p>
<h2 id="composition"><a class="header" href="#composition">Composition</a></h2>
<pre><code class="language-json">{
  "models": {
    "llm": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "llm",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "assistant",
      "layer": 1,
      "model": "llm",
      "adapter": "openai-api",
      "use-case": "General assistant for all queries",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="running"><a class="header" href="#running">Running</a></h2>
<pre><code class="language-bash">ollama serve
llmnet serve basic-chatbot.json
curl http://localhost:8080/v1/chat/completions \
  -d '{"messages": [{"role": "user", "content": "Hello!"}]}'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="dual-expert-pipeline"><a class="header" href="#dual-expert-pipeline">Dual Expert Pipeline</a></h1>
<p>Route requests to specialized domain experts.</p>
<h2 id="composition-1"><a class="header" href="#composition-1">Composition</a></h2>
<pre><code class="language-json">{
  "models": {
    "router": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    },
    "expert": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "router",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "sales-expert",
      "layer": 1,
      "model": "expert",
      "adapter": "openai-api",
      "use-case": "Sales inquiries, pricing, product information",
      "context": "You are a sales expert. Be helpful and informative about products.",
      "output-to": ["output"]
    },
    {
      "name": "support-expert",
      "layer": 1,
      "model": "expert",
      "adapter": "openai-api",
      "use-case": "Technical support, troubleshooting, bug reports",
      "context": "You are a technical support expert. Help solve problems.",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<ol>
<li>User sends a message</li>
<li>Router analyzes the message and selects the best expert</li>
<li>Selected expert generates the response</li>
<li>Response is returned to user</li>
</ol>
<h2 id="testing"><a class="header" href="#testing">Testing</a></h2>
<pre><code class="language-bash"># Sales query
curl http://localhost:8080/v1/chat/completions \
  -d '{"messages": [{"role": "user", "content": "What are your pricing options?"}]}'

# Support query
curl http://localhost:8080/v1/chat/completions \
  -d '{"messages": [{"role": "user", "content": "My app keeps crashing on startup"}]}'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multi-layer-pipeline"><a class="header" href="#multi-layer-pipeline">Multi-Layer Pipeline</a></h1>
<p>Chain responses through multiple processing layers.</p>
<h2 id="composition-2"><a class="header" href="#composition-2">Composition</a></h2>
<pre><code class="language-json">{
  "models": {
    "model": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "model",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "draft-writer",
      "layer": 1,
      "model": "model",
      "adapter": "openai-api",
      "use-case": "Write initial draft response",
      "output-to": [2]
    },
    {
      "name": "editor",
      "layer": 2,
      "model": "model",
      "adapter": "openai-api",
      "use-case": "Edit and improve the draft",
      "context": "Improve clarity and fix any errors in the text.",
      "output-to": [3]
    },
    {
      "name": "fact-checker",
      "layer": 3,
      "model": "model",
      "adapter": "openai-api",
      "use-case": "Verify facts and add citations",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="flow"><a class="header" href="#flow">Flow</a></h2>
<pre><code>Router → Draft Writer → Editor → Fact Checker → Output
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="conditional-routing-1"><a class="header" href="#conditional-routing-1">Conditional Routing</a></h1>
<p>Route based on input characteristics.</p>
<h2 id="composition-3"><a class="header" href="#composition-3">Composition</a></h2>
<pre><code class="language-json">{
  "models": {
    "model": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "model",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "quick-responder",
      "layer": 1,
      "model": "model",
      "adapter": "openai-api",
      "use-case": "Quick, concise answers",
      "if": "$WORD_COUNT &lt; 10",
      "output-to": ["output"]
    },
    {
      "name": "detailed-responder",
      "layer": 1,
      "model": "model",
      "adapter": "openai-api",
      "use-case": "Detailed, comprehensive answers",
      "if": "$WORD_COUNT &gt;= 10",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="testing-1"><a class="header" href="#testing-1">Testing</a></h2>
<pre><code class="language-bash"># Short query → quick-responder
curl -d '{"messages": [{"role": "user", "content": "Hi there"}]}'

# Long query → detailed-responder
curl -d '{"messages": [{"role": "user", "content": "Can you explain in detail how machine learning models are trained and what factors affect their performance?"}]}'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multiplication-calculator-with-hooks"><a class="header" href="#multiplication-calculator-with-hooks">Multiplication Calculator with Hooks</a></h1>
<p>This example demonstrates hooks in action with a fun arithmetic pipeline:</p>
<ol>
<li>User asks: “What’s 2*4?”</li>
<li>LLM returns JSON with the result</li>
<li>Post-hook validates the answer</li>
<li>If valid, a second LLM doubles it</li>
<li>Post-hook validates again</li>
<li>Final result is output</li>
</ol>
<h2 id="the-composition"><a class="header" href="#the-composition">The Composition</a></h2>
<pre><code class="language-json">{
  "secrets": {
    "validator": {
      "source": "env",
      "variable": "VALIDATOR_API_KEY"
    }
  },
  "functions": {
    "validate-math": {
      "type": "rest",
      "method": "POST",
      "url": "http://localhost:8090/validate",
      "body": {
        "expression": "$INPUT",
        "result": "$OUTPUT"
      },
      "timeout": 5
    }
  },
  "models": {
    "calculator": {
      "type": "external",
      "interface": "openai-api",
      "url": "http://localhost:11434/v1",
      "api-key": "ollama"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "calculator",
      "adapter": "openai-api",
      "output-to": [1]
    },
    {
      "name": "initial-calc",
      "layer": 1,
      "model": "calculator",
      "adapter": "openai-api",
      "use-case": "Calculate the initial multiplication and return JSON only",
      "context": "You are a calculator. Return ONLY a JSON object with the format: {\"result\": &lt;number&gt;}. No explanation.",
      "hooks": {
        "post": [
          {
            "function": "validate-math",
            "mode": "transform",
            "on_failure": "abort"
          }
        ]
      },
      "output-to": [2]
    },
    {
      "name": "doubler",
      "layer": 2,
      "model": "calculator",
      "adapter": "openai-api",
      "use-case": "Double the previous result",
      "context": "You receive a number. Double it and return ONLY a JSON object: {\"result\": &lt;number&gt;}. No explanation.",
      "hooks": {
        "post": [
          {
            "function": "validate-math",
            "mode": "transform",
            "on_failure": "abort"
          }
        ]
      },
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="the-validation-server"><a class="header" href="#the-validation-server">The Validation Server</a></h2>
<p>Here’s a simple validation server in Python that checks if the LLM’s math is correct:</p>
<pre><code class="language-python"># validator_server.py
from flask import Flask, request, jsonify
import json
import re

app = Flask(__name__)

def extract_result(text):
    """Extract the result from JSON or plain number."""
    try:
        data = json.loads(text)
        return data.get("result")
    except:
        # Try to find a number in the text
        match = re.search(r"(\d+(?:\.\d+)?)", text)
        return float(match.group(1)) if match else None

def evaluate_expression(expr):
    """Safely evaluate a simple math expression."""
    # Only allow basic multiplication
    match = re.match(r".*?(\d+)\s*\*\s*(\d+).*", expr)
    if match:
        return int(match.group(1)) * int(match.group(2))

    # If input is just a number (for doubling), return it doubled
    match = re.search(r'"?result"?\s*:\s*(\d+)', expr)
    if match:
        return int(match.group(1)) * 2

    return None

@app.route("/validate", methods=["POST"])
def validate():
    data = request.json
    expression = data.get("expression", "")
    output = data.get("result", "")

    # Extract the result from LLM output
    llm_result = extract_result(output)
    if llm_result is None:
        return jsonify({"error": "Could not parse result"}), 400

    # Calculate expected result
    expected = evaluate_expression(expression)

    # For doubling, check if it's double the input
    if expected is None:
        # Maybe it's a doubling operation
        match = re.search(r'"?result"?\s*:\s*(\d+)', expression)
        if match:
            expected = int(match.group(1)) * 2

    # Validate
    if expected is not None and abs(llm_result - expected) &lt; 0.01:
        # Return the validated result (transform mode)
        return jsonify({"result": int(llm_result)})
    else:
        return jsonify({
            "error": f"Math error: expected {expected}, got {llm_result}"
        }), 400

if __name__ == "__main__":
    app.run(port=8090)
</code></pre>
<h2 id="running-the-example"><a class="header" href="#running-the-example">Running the Example</a></h2>
<h3 id="1-start-the-validator-server"><a class="header" href="#1-start-the-validator-server">1. Start the Validator Server</a></h3>
<pre><code class="language-bash">pip install flask
python validator_server.py
</code></pre>
<h3 id="2-start-ollama-1"><a class="header" href="#2-start-ollama-1">2. Start Ollama</a></h3>
<pre><code class="language-bash">ollama serve
ollama pull llama3.2:3b
</code></pre>
<h3 id="3-run-the-pipeline"><a class="header" href="#3-run-the-pipeline">3. Run the Pipeline</a></h3>
<pre><code class="language-bash">llmnet serve calculator.json
</code></pre>
<h3 id="4-test-it"><a class="header" href="#4-test-it">4. Test It</a></h3>
<pre><code class="language-bash"># Ask "What's 2*4?"
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "What is 2*4?"}]}'
</code></pre>
<p>Expected flow:</p>
<ol>
<li>Router → initial-calc</li>
<li>initial-calc LLM returns <code>{"result": 8}</code></li>
<li>validate-math hook confirms 2*4=8 ✓</li>
<li>Pass to doubler</li>
<li>doubler LLM returns <code>{"result": 16}</code></li>
<li>validate-math hook confirms 8*2=16 ✓</li>
<li>Output: <code>{"result": 16}</code></li>
</ol>
<h2 id="key-concepts-demonstrated"><a class="header" href="#key-concepts-demonstrated">Key Concepts Demonstrated</a></h2>
<h3 id="transform-hooks"><a class="header" href="#transform-hooks">Transform Hooks</a></h3>
<p>The <code>validate-math</code> function uses <code>"mode": "transform"</code>, meaning:</p>
<ul>
<li>It waits for the validation to complete</li>
<li>If validation passes, the response is used as the new output</li>
<li>If validation fails (HTTP 4xx/5xx), the pipeline aborts</li>
</ul>
<h3 id="hook-chaining-1"><a class="header" href="#hook-chaining-1">Hook Chaining</a></h3>
<p>Each layer has its own post-hook validation, creating a chain of verified computations.</p>
<h3 id="abort-on-failure"><a class="header" href="#abort-on-failure">Abort on Failure</a></h3>
<p>Using <code>"on_failure": "abort"</code> ensures that math errors stop the pipeline rather than propagating incorrect values.</p>
<h2 id="extending-the-example"><a class="header" href="#extending-the-example">Extending the Example</a></h2>
<h3 id="add-logging"><a class="header" href="#add-logging">Add Logging</a></h3>
<pre><code class="language-json">{
  "functions": {
    "log-calculation": {
      "type": "rest",
      "method": "POST",
      "url": "http://localhost:8091/log",
      "body": {
        "input": "$INPUT",
        "output": "$OUTPUT",
        "node": "$NODE",
        "timestamp": "$TIMESTAMP"
      }
    }
  }
}
</code></pre>
<p>Then add to each node:</p>
<pre><code class="language-json">"hooks": {
  "post": [
    {"function": "log-calculation", "mode": "observe"},
    {"function": "validate-math", "mode": "transform", "on_failure": "abort"}
  ]
}
</code></pre>
<h3 id="add-conditional-validation"><a class="header" href="#add-conditional-validation">Add Conditional Validation</a></h3>
<p>Only validate for longer expressions:</p>
<pre><code class="language-json">{
  "function": "validate-math",
  "mode": "transform",
  "on_failure": "abort",
  "if": "$WORD_COUNT &gt;= 3"
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="openrouter-integration"><a class="header" href="#openrouter-integration">OpenRouter Integration</a></h1>
<p>Use multiple models via OpenRouter.</p>
<h2 id="composition-4"><a class="header" href="#composition-4">Composition</a></h2>
<pre><code class="language-json">{
  "secrets": {
    "openrouter": {
      "source": "env",
      "variable": "OPENROUTER_API_KEY"
    }
  },
  "models": {
    "fast-router": {
      "type": "external",
      "interface": "openai-api",
      "url": "https://openrouter.ai/api/v1",
      "api-key": "$secrets.openrouter.OPENROUTER_API_KEY"
    },
    "powerful-handler": {
      "type": "external",
      "interface": "openai-api",
      "url": "https://openrouter.ai/api/v1",
      "api-key": "$secrets.openrouter.OPENROUTER_API_KEY"
    }
  },
  "architecture": [
    {
      "name": "router",
      "layer": 0,
      "model": "fast-router",
      "adapter": "openai-api",
      "extra-options": {
        "model_override": "meta-llama/llama-3.2-3b-instruct"
      },
      "output-to": [1]
    },
    {
      "name": "expert",
      "layer": 1,
      "model": "powerful-handler",
      "adapter": "openai-api",
      "extra-options": {
        "model_override": "anthropic/claude-3.5-sonnet"
      },
      "use-case": "Expert responses using a powerful model",
      "output-to": ["output"]
    },
    {
      "name": "output",
      "adapter": "output"
    }
  ]
}
</code></pre>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<pre><code class="language-bash">export OPENROUTER_API_KEY=sk-or-...
llmnet serve openrouter-pipeline.json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="hook-execution"><a class="header" href="#hook-execution">Hook Execution</a></h1>
<p>Deep dive into how hooks are executed in the pipeline.</p>
<h2 id="execution-order"><a class="header" href="#execution-order">Execution Order</a></h2>
<ol>
<li><strong>Request arrives</strong> at a node</li>
<li><strong>Pre-hooks execute</strong> in order
<ul>
<li>Each hook can modify input (transform mode)</li>
<li>Or observe without modifying (observe mode)</li>
</ul>
</li>
<li><strong>LLM call</strong> with (possibly modified) input</li>
<li><strong>Post-hooks execute</strong> in order
<ul>
<li>Each hook can modify output</li>
<li>Or observe without modifying</li>
</ul>
</li>
<li><strong>Result passed</strong> to next node</li>
</ol>
<h2 id="observe-mode-details"><a class="header" href="#observe-mode-details">Observe Mode Details</a></h2>
<pre><code>┌─────────────────────────────────────┐
│           Observe Hook              │
│  ┌─────────────────────────────┐   │
│  │ 1. Spawn async task         │   │
│  │ 2. Execute function         │   │
│  │ 3. Log result (success/fail)│   │
│  └─────────────────────────────┘   │
│  Pipeline continues immediately    │
└─────────────────────────────────────┘
</code></pre>
<ul>
<li>Non-blocking: pipeline doesn’t wait</li>
<li>Fire-and-forget: result is logged but not used</li>
<li>Failures are logged but don’t affect pipeline</li>
<li>Perfect for: logging, metrics, notifications</li>
</ul>
<h2 id="transform-mode-details"><a class="header" href="#transform-mode-details">Transform Mode Details</a></h2>
<pre><code>┌─────────────────────────────────────┐
│          Transform Hook             │
│  ┌─────────────────────────────┐   │
│  │ 1. Execute function (await) │   │
│  │ 2. Check success/failure    │   │
│  │ 3. Apply output as new data │   │
│  └─────────────────────────────┘   │
│  Pipeline waits for completion     │
└─────────────────────────────────────┘
</code></pre>
<ul>
<li>Blocking: pipeline waits for result</li>
<li>Result replaces current data</li>
<li>Failures can abort or continue</li>
<li>Perfect for: validation, transformation, enrichment</li>
</ul>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<h3 id="continue-on-failure"><a class="header" href="#continue-on-failure">Continue on Failure</a></h3>
<pre><code class="language-json">{"function": "validate", "mode": "transform", "on_failure": "continue"}
</code></pre>
<ul>
<li>Error is logged</li>
<li>Original data is preserved</li>
<li>Pipeline continues</li>
</ul>
<h3 id="abort-on-failure-1"><a class="header" href="#abort-on-failure-1">Abort on Failure</a></h3>
<pre><code class="language-json">{"function": "validate", "mode": "transform", "on_failure": "abort"}
</code></pre>
<ul>
<li>Error returned to caller</li>
<li>Pipeline stops</li>
<li>No further hooks execute</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="variable-substitution-1"><a class="header" href="#variable-substitution-1">Variable Substitution</a></h1>
<p>Variables allow dynamic values in functions and hooks.</p>
<h2 id="available-variables-1"><a class="header" href="#available-variables-1">Available Variables</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Variable</th><th>Scope</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>$INPUT</code></td><td>Pre/Post</td><td>Current input content</td></tr>
<tr><td><code>$OUTPUT</code></td><td>Post only</td><td>LLM output</td></tr>
<tr><td><code>$NODE</code></td><td>Pre/Post</td><td>Current node name</td></tr>
<tr><td><code>$PREV_NODE</code></td><td>Pre/Post</td><td>Previous node name</td></tr>
<tr><td><code>$TIMESTAMP</code></td><td>Pre/Post</td><td>ISO 8601 timestamp</td></tr>
<tr><td><code>$REQUEST_ID</code></td><td>Pre/Post</td><td>Unique request ID</td></tr>
</tbody>
</table>
</div>
<h2 id="secret-variables"><a class="header" href="#secret-variables">Secret Variables</a></h2>
<p>Access secrets with: <code>$secrets.{name}.{variable}</code></p>
<pre><code class="language-json">"Authorization": "Bearer $secrets.api.TOKEN"
</code></pre>
<h2 id="substitution-in-bodies"><a class="header" href="#substitution-in-bodies">Substitution in Bodies</a></h2>
<p>Variables work in JSON bodies:</p>
<pre><code class="language-json">{
  "body": {
    "node": "$NODE",
    "input": "$INPUT",
    "timestamp": "$TIMESTAMP"
  }
}
</code></pre>
<h2 id="nested-substitution"><a class="header" href="#nested-substitution">Nested Substitution</a></h2>
<p>Variables are substituted recursively in objects and arrays:</p>
<pre><code class="language-json">{
  "body": {
    "data": {
      "nested": {
        "value": "$INPUT"
      }
    },
    "list": ["$NODE", "$TIMESTAMP"]
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h1>
<p>How llmnet handles errors throughout the pipeline.</p>
<h2 id="hook-errors"><a class="header" href="#hook-errors">Hook Errors</a></h2>
<h3 id="observe-mode"><a class="header" href="#observe-mode">Observe Mode</a></h3>
<ul>
<li>Errors are logged</li>
<li>Pipeline continues unaffected</li>
<li>Good for non-critical operations</li>
</ul>
<h3 id="transform-mode-with-continue"><a class="header" href="#transform-mode-with-continue">Transform Mode with Continue</a></h3>
<ul>
<li>Error is logged</li>
<li>Original data is preserved</li>
<li>Pipeline continues with unchanged data</li>
</ul>
<h3 id="transform-mode-with-abort"><a class="header" href="#transform-mode-with-abort">Transform Mode with Abort</a></h3>
<ul>
<li>Error returned to caller</li>
<li>Pipeline stops immediately</li>
<li>Subsequent hooks don’t execute</li>
</ul>
<h2 id="llm-errors"><a class="header" href="#llm-errors">LLM Errors</a></h2>
<ul>
<li>Network failures are retried (configurable)</li>
<li>Timeout errors abort the request</li>
<li>Invalid responses trigger error</li>
</ul>
<h2 id="validation-errors"><a class="header" href="#validation-errors">Validation Errors</a></h2>
<p>Use <code>llmnet validate</code> to catch:</p>
<ul>
<li>Missing required fields</li>
<li>Invalid model references</li>
<li>Undefined functions in hooks</li>
<li>Missing output node</li>
</ul>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Use abort for critical validation</strong>: If bad data would cause problems downstream</li>
<li><strong>Use continue for logging</strong>: Never let logging failures stop your pipeline</li>
<li><strong>Set appropriate timeouts</strong>: Prevent hung connections</li>
<li><strong>Validate before deploy</strong>: Always run <code>llmnet validate</code></li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
